---
title: "线性模型"
author: "金林"
date: "2019-03"
output:
  beamer_presentation:
    keep_tex: true
    latex_engine: xelatex
    pandoc_args:
    - --listing
    - --filter
    - pandoc-crossref
    slide_level: 3
    template: ./style/beamer-template.tex
  bookdown::html_document2:
    fig_caption: true
    highlight: haddock
    keep_md: true
    md_extensions: +east_asian_line_breaks
    number_sections: true
    pandoc_args:
    - --filter
    - pandoc-crossref
    - -M
    - eqnPrefix=
    seq_numbering: false
    toc: true
  bookdown::pdf_document2:
    keep_tex: true
    latex_engine: xelatex
    md_extensions: +east_asian_line_breaks
    pandoc_args:
    - --listing
    - --filter
    - pandoc-crossref
    toc: false
  bookdown::word_document2:
    fig_caption: true
    md_extensions: +east_asian_line_breaks
    pandoc_args:
    - --filter
    - pandoc-crossref
    reference_docx: ./style/word-styles-02.docx
  ioslides_presentation:
    highlight: haddock
    slide_level: 3
css: ./style/markdown.css
csl: ./style/chinese-gb7714-2005-numeric.csl
bibliography: Bibfile.bib
eqnPrefixTemplate: ($$i$$)
institute: "中南财经政法大学统计系"
link-citations: true
linkReferences: true
chapters: true
tableEqns: false
autoEqnLabels: false
---


```{r setup, echo=F}
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = FALSE, results = 'hide')
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

```{r prepare}
rm(list=ls())
options(digits=4)
options(scipen=100)
graphics.off()
Sys.setlocale("LC_ALL", "Chinese")
```

# 多元线性回归模型及其基本假定
	
## 多元线性回归模型的基本形式
### 一般形式

多元线性回归模型是指描述因变量 $y$ 与一组自变量 $x_1,x_2, \ldots ,x_p$ 以及随机误差项 $\varepsilon$的
关系的等式。其一般表达式为：

$$y = \beta _0 + \beta _1{x_1} + \beta _2{x_2} +  \cdots  +\beta _p{x_p}+ \varepsilon$$ {#eq:model1}

式中， $\beta_0,\beta_1,\beta_2,\cdots,\beta_p$ 是 $p+1$ 个未知参数， $\beta_0$
称为回归截距， $\beta_1,\cdots,\beta_p$称为回归系数， $\varepsilon$ 是随机误差项。
$y$称为被解释变量（因变量），而 $x_1,x_2,\dots,x_p$是 $p$ 个可以精确测量并可控制
的自变量，称为解释变量。 $p=1$时，式 [@eq:model1] 即为一元线性回归模型， $p \ge
2$ 时，则称式 [@eq:model1] 为多元线性回归模型。

### 样本形式

对于一个实际问题，如果获得 $n$ 组观测数据 $(x_{i1},x_{i2}, \cdots ,x_{ip};y_i)(i = 1,2 \cdots ,n)$ ，
则线性回归模型式 [@eq:model1] 可表示为：

$$\left\{ \begin{array}{l}
y_1 = \beta _0 + \beta _1{x_{11}} + \beta _2{x_{12}} +  \cdots \beta _p{x_{1p}} + \varepsilon _1\\
y_2 = \beta _0 + \beta _1{x_{21}} + \beta _2{x_{22}} +  \cdots \beta _p{x_{2p}} + \varepsilon _2\\
 \cdots  \cdots  \cdots  \cdots \\
y_n = \beta _0 + \beta _1{x_{n1}} + \beta _2{x_{n2}} +  \cdots \beta _p{x_{np}} + \varepsilon _n
\end{array} \right.$$ {#eq:model2}

### 矩阵形式

写成矩阵形式为： 

$$Y = X{\boldsymbol {\beta}}  + {\boldsymbol {\varepsilon}}$$ {#eq:model3}

式中，

$$Y = \left[ \begin{array}{c} y_1\\y_2\\\vdots \\y_n \end{array} \right],
X = \left[ \begin{array}{ccccc} 1&x_{11}&x_{12}&\cdots&x_{1p}\\ 1&x_{21}&x_{22}&\cdots&x_{2p}\\
\vdots & \vdots & \vdots & \ddots & \vdots \\ 1&x_{n1}&x_{n2}&\cdots&x_{np}\end{array} \right],
\beta  = \left[ \begin{array}{l} \beta _0\\ \beta _1\\ \vdots \\ \beta _p \end{array} \right],
\varepsilon  = \left[ \begin{array}{l} \varepsilon _1\\ \varepsilon _2\\ \vdots \\ \varepsilon _n
\end{array} \right]$$

### 随机误差

矩阵 $X$ 是一个 $n \times (p+1)$ 的矩阵，常称为设计矩阵。随机误差$\varepsilon$
与一元线性回归的假定类似，多元线性回归对随机误差项也假定：

$$\left\{ \begin{array}{l} E(\varepsilon ) = 0\\ Var(\varepsilon ) = \sigma ^2 \end{array} 
\right.$$ 


## 多元线性回归模型的基本假定

为了方便地进行模型的参数估计，对回归方程式 [@eq:model2] 有如下的基本假定：

### 解释变量

(1)解释变量 $x_1,x_2,\cdots,x_p$ 是确定性变量，即非随机变量，且要求设计矩阵的秩
$rank(X)=p+1<n$ 。这表明设计矩阵 $X$ 中的自变量列之间不相关，且样本容量的个数
$n$ 应大于自变量的个数 $p$ ，$X$ 是列满秩矩阵。

### 随机误差项

(2)随机误差项具有零均值和等方差，即:

$$\left\{ \begin{array}{l}
E({\varepsilon _i}) = 0,\;\;i = 1,\;2,\;\cdots ,\;n\\
{{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = \left\{ \begin{array}{l}
{\sigma ^2},\;\;i = j\\
0,\;i \ne j
\end{array} \right.\;\;\;\;\;\;\;(i,\;j = 1,\;2,\;\cdots,\;n)
\end{array} \right.$$


这个假定常称为高斯－马尔可夫条件。 $E({\varepsilon _i}) = 0$ ，即假设观测值没有
系统误差，随机误差 $\varepsilon_i$
的平均值为零。 ${\mathop{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = 0,i \ne
j$ ，即随机误差 $\varepsilon _i$ 的协方差为0,表明任意不同的两个样本的随机误差项
是不相关的。 ${\mathop{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = {\sigma
^2}, i = j$表明各随机误差项的方差相同。

### 正态假设

(3)正态分布的假定条件为：

$$\left\{ \begin{array}{l}
{\varepsilon _i}\sim N(0,\;{\sigma ^2}),\;\;i = 1,\;2,\; \cdots ,\;n\\
{\varepsilon _1},{\varepsilon _2}, \cdots ,{\varepsilon _n} \text{相互独立}
\end{array} \right.$$ 

对于多元线性回归的矩阵形式 [@eq:model3]，这个条件便可表示为：
$$\boldsymbol {\varepsilon}\overset{\text{i.i.d}}  \sim N(0,\sigma^2I_n)$$ 
由上述假定和多元正态分布的性质可知，随机向量 $Y$ 服从 $n$ 维正态分布，回归模型式 [@eq:model3] 的期望向量
$$\begin{array}{l}E(Y)=X\;\boldsymbol{\beta}\\Var(Y)=\sigma^2I_n\end{array}$$ 
因此有
$$Y\overset{\text{i.i.d}} \sim N(X\;\boldsymbol\beta,\sigma^2I_n)$$ 

### 总体回归方程

对于给定的 $X$ ，因变量 $Y$ 是随机变量，有多个不同的取值，这些不同的取值服从正态分布。
而 $Y$ 的条件期望值 $E(Y|X)$ 是 $X$ 的线性函数，以下将条件期望 $E(Y|X)$ 简记为 $E(Y)$ 。即

$$E(Y)=X\;\boldsymbol\beta$$ {#eq:model11}

或

$$E(y)=\beta _0 + \beta _1{x_1} + \beta _2{x_2} +  \cdots  +\beta _p{x_p}$$ {#eq:model12}

式 [@eq:model12] 称为总体回归方程或理论回归方程，式 [@eq:model11] 是式 [@eq:model12] 的矩阵表达。

# 多元线性回归模型参数的估计

### 样本多元线性回归函数

多元线性回归方程的参数 $\beta_0, \beta_1, \cdots, \beta_p$ 是未知的，需要利用样本数据去估计它们。当用样
本统计量 $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 去估计线性回归方程的参数 
$\beta_0, \beta_1, \cdots, \beta_p$ 时，得到了估计的多元回归方程,即样本多元线性回归函数。其一般表达形式

$$\hat y = \hat \beta_0 + \hat \beta _1 x_1 + \cdots + \hat \beta _p x_p $$ {#eq:model14}

其随机表达式为

$$y=\hat \beta_0 + \hat \beta _1 x_1 + \cdots + \hat \beta _p x_p + e$$ {#eq:model15}

式中，$\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 为参数 $\beta_0, \beta_1, \cdots, \beta_p$  的
估计值； $\hat y$ 为 $E(y)$ 的估计值； $e$ 为 $\varepsilon$ 的估计值。 


## 模型参数的估计

### 离差平方和

多元线性回归方程参数的估计与一元线性回归方程的参数估计原理一样，仍然采用最小二乘估计法。

即寻找参数 $\beta_0, \beta_1, \cdots, \beta_p$ 的估计值 ，使离差平方和

$$ Q = \sum\limits_{i = 1}^n {\mathop {(\mathop y\nolimits_i  - \mathop {\hat y}\nolimits_i )}\nolimits^2 } 
= \sum\limits_{i = 1}^n {{{({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} 
-  \cdots  - {{\hat \beta }_p}{x_{ip}})}^2}} $$ {#eq:model16}

达到最小。

### 求极值

由于式 [@eq:model16] 是关于 $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 的非负二次函数，因而它的最小
值总是存在的。根据微积分中求极值的原理， $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 应满足
下列方程组：

$$\left\{ \begin{array}{l}
\frac{{\partial Q}}{{\partial {\beta _0}}}{|_{{\beta _0} = {{\hat \beta }_0}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}})}  = 0\\
\frac{{\partial Q}}{{\partial {\beta _1}}}{|_{{\beta _1} = {{\hat \beta }_1}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{i1}}}  = 0\\
\frac{{\partial Q}}{{\partial {\beta _2}}}{|_{{\beta _2} = {{\hat \beta }_2}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{i2}}}  = 0\\
 \cdots  \cdots  \cdots \\
\frac{{\partial Q}}{{\partial {\beta _p}}}{|_{{\beta _p} = {{\hat \beta }_p}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{ip}}}  = 0
\end{array} \right.$$ {#eq:model17}

### 估计量

以上方程组经整理后，得到用矩阵形式表示的正规方程组：
$${X^T}(Y - X\hat {\boldsymbol{\beta}} ) = 0$$ {#eq:model18}
移项得：
$${X^T}X\hat {\boldsymbol{\beta}}  = {X^T}Y$$ {#eq:model19}

当 $({X^T}X)^{ - 1}$ 存在时，即得模型参数的最小二乘估计为：
$$\hat {\boldsymbol{\beta}}  = ({X^T}X)^{ - 1}{X^T}Y$$ {#eq:model20}
依照式 [@eq:model20]求解 $\hat \beta _0, \hat \beta _1,\hat \beta _2,\cdots , \hat \beta _p$ 的表达式称为模型参数
$\beta_0,\beta_1,\beta_2,\cdots, \beta_p$ 的最小二乘估计量。

### 求极值的矩阵表达

$$\hat {\boldsymbol\varepsilon}^T \hat {\boldsymbol\varepsilon}=\sum_{i=1}^n(y_i- {\boldsymbol x_i}^T\hat{\boldsymbol\beta})^2=(\boldsymbol y-\boldsymbol X\hat{\boldsymbol\beta})^T(\boldsymbol y-\boldsymbol X\hat{\boldsymbol\beta})$$ 

上式中 ${\boldsymbol x_i}^T=(1,x_{i1},\cdots,x_{ik})$ 表示 矩阵 $\boldsymbol X$ 的第 $i$ 行。当把
$(\boldsymbol y-\boldsymbol X\hat{\boldsymbol\beta})^T(\boldsymbol y-\boldsymbol X\hat{\boldsymbol\beta})$ 的乘积展开时，可以合并四项中的两项，得到

$$\hat {\boldsymbol\varepsilon}^T \hat {\boldsymbol\varepsilon}=\boldsymbol y^T\boldsymbol y-2\boldsymbol y^T\boldsymbol X\hat{\boldsymbol\beta}+\hat{\boldsymbol\beta}^T\boldsymbol X^T\boldsymbol X \hat{\boldsymbol\beta}$$

通过对上式求关于 $\hat{\boldsymbol\beta}$ 的导数，并令其导函数为0，可以得到 $\hat{\boldsymbol\beta}$
的值，该值使得 $\hat {\boldsymbol\varepsilon}^T \hat {\boldsymbol\varepsilon}$ 最小，即：

$$\frac{\partial {\hat {\boldsymbol\varepsilon}^T \hat {\boldsymbol\varepsilon}}}{\partial{\hat{\boldsymbol\beta}}}=\boldsymbol0-2\boldsymbol X^T\boldsymbol y+2\boldsymbol X^T\boldsymbol X\hat {\boldsymbol \beta}=0$$

利用上式即可得到正规方程组的矩阵表达形式：

$$\boldsymbol X^T\boldsymbol X\hat {\boldsymbol \beta}=\boldsymbol X^T\boldsymbol y$$

## 最小二乘估计量的性质
### 线性性
多元回归模型中模型参数的最小二乘估计量是最优线性无偏估计量(BLUE)。

(1) 线性性

 ${\boldsymbol{\beta}}$ 是随机向量 $Y$ 的一个线性变换，应用普通最小二乘法估计得到的回归系数向量 ${\boldsymbol{\beta}}$ 的估
计量为：

$$\hat {\boldsymbol{\beta}}  = ({X^T}X)^{ - 1}{X^T}Y$$ {#eq:model21}

根据回归模型假设知，$X$ 是固定的设计矩阵，因此， $\hat {\boldsymbol{\beta}}$ 是 $Y$ 的一个线性变换。

### 无偏性

(2) $\hat {\boldsymbol{\beta}}$ 是 ${\boldsymbol{\beta}}$ 的无偏估计。

证明：

$$\begin{aligned}
E(\hat {\boldsymbol{\beta}}) &= E[({X^T}X)^{ - 1}{X^T}Y]\\&=({X^T}X)^{ - 1}{X^T}E(X{\boldsymbol{\beta}}  + {\boldsymbol{\varepsilon}})
\\&=({X^T}X)^{ - 1}({X^T}X){\boldsymbol{\beta}}\\&={\boldsymbol{\beta}}
\end{aligned}$$ {#eq:model22}

### 有效性

最优一词的含义就是指方差最小。给定一群线性无偏估计量，普通最小二乘估计量的方差最小。
模型参数最小二乘估计量的方差、协方差矩阵为：
$$\begin{aligned} 
D(\hat {\boldsymbol{\beta}} ) &= {\mathop{\rm cov}} (\hat {\boldsymbol{\beta}} ,\;\hat {\boldsymbol{\beta}} ) 
\\&= E(\hat {\boldsymbol{\beta}}  - \hat {\boldsymbol{\beta}} )(\hat {\boldsymbol{\beta}}  - \hat {\boldsymbol{\beta}} )^T
\\&= \sigma ^2({X^T}X)^{ - 1}
\end{aligned}$$ {#eq:model23}

证明：
$$\begin{aligned}
D(\hat {\boldsymbol{\beta}} ) &= {\mathop{\rm cov}} (\hat {\boldsymbol{\beta}},\;\hat {\boldsymbol{\beta}} ) 
\\&= ({X^T}X)^{ - 1}X^T {\mathop{\rm cov}}(Y,Y)(({X^T}X)^{ - 1}X^T)^T
\\&=({X^T}X)^{ - 1}X^T \sigma ^2X({X^T}X)^{ - 1}
\\&=\sigma ^2({X^T}X)^{- 1}\end{aligned}$$ {#eq:model24}

该矩阵主对角元素是各回归系数估计量的方差 ，其他元素是各模型参数估计量之间的协方
差$E(\hat \beta _i - \beta_i)(\hat \beta _j - \beta _j)\;\;(i \ne j)$ 。

## 多元线性回归函数的拟合优度

### 样本决定系数

样本复决定系数是回归平方和与总离差平方和之比，记为 $R^2$ 。该统计量可作为评价模
型拟合优度的一项指标。

利用总离差平方和的分解式:

$$\sum\limits_{i = 1}^n {(y_i - \bar y)^2}  = \sum\limits_{i = 1}^n {({\hat y}_i - \bar y)}^2  + 
\sum\limits_{i = 1}^n {(y_i - {\hat y}_i)}^2 $$ {#eq:model25}

上式可写为： 总离差平方和(SST)=回归平方和(SSR)+残差平方和(SSE), 可得到样本复决定系数的计算公
式为：

$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$ {#eq:model26}

### 调整样本决定系数

样本决定系数随着自变量个数增加而增大。在多元线性回归模型中，各回归模型所含的变量
的数目未必相同，以 $R^2$ 的大小作为衡量模型拟合优度的指标就不太合适。因此，在多
元回归分析中应该使用自由度调整后的决定系数，即利用各自的自由度对总离差平方和与残
差平方和进行调整，然后再计算调整后的决定系数 $\bar R^2$ 。

$$\bar R^2 = 1 - \frac{SSE/(n - p - 1)}{SST/(n - 1)} = 1 - \frac{n - 1}{n - p - 1}(1 - R^2)$$ {#eq:model27}

显然有 $\bar R^2 \le R^2$ , $\bar R^2$ 随着自变量的增加并不一定增大。由式 [@eq:model27] 可以看到，尽管 $1-R^2$ 
随着自变量个数的增加而减少，但由于其前面的系数 $(n-1)/(n-p-1)$ 起加权作用，使 $\bar R^2$ 随着自变量的增加并
不一定增大。当所增加的自变量对回归的贡献很小时， $\bar R^2$ 反而可能减少。

样本决定系数 $R^2$ 的取值在[0，1]区间内，由式 [@eq:model27] 可知 $\bar R^2$ 小于1，但不一定都大于0，在拟合极差
的场合， $\bar R^2$ 可能为负值。一般而言， $\bar R^2$ 越接近1，表明拟合效果越好; $\bar R^2$  越接近0或小于0表明
回归拟合的效果越差。

### 总体方差的估计

除了回归系数以外，多元线性回归模型中还包含了随机误差项的方差 $\sigma^2$ 这个未知参数。与一元线性回归
分析相似，多元线性回归模型中的 $\sigma^2$ 也是利用残差平方和除以其自由度来估计的，即有

$${\hat \sigma ^2} = \frac{{SSE}}{{n - p - 1}} = \frac{{\sum\limits_{i = 1}^n {\mathop {(\mathop y\nolimits_i  - \mathop {\hat y}\nolimits_i )}\nolimits^2 } }}{{n - p - 1}}$$ {#eq:model28} 

式中， $n$ 是样本容量, $p$ 是模型中自变量个数， $\hat \sigma^2$ 是随机误差项方差 $\sigma^2$ 的无偏估计量。
 
# 多元线性回归中的显著性检验和参数区间估计

## 显著性检验

与一元线性回归分析同理，当求出估计的线性回归方程后，还需对回归系数的显著性进行 $t$ 检验和对回归方程的显著性进行 
 $F$ 检验。多元线性回归方程的显著性检验，与一元线性回归方程的显著性检验既有相同之处，也有不同之处。在一元线性回
归中，回归方程的 $F$ 检验与回归系数的 $t$ 检验是等价的。但在多元线性回归分析中，这两种检验是不等价的。多元线性
回归分析中的 $F$ 检验主要是检验因变量 $y$ 与多个自变量整体线性关系的显著性，在 $p$ 个自变量中，只要有一个自变量
与 $y$ 线性关系显著， $F$ 检验就能通过，但并不意味着 $p$ 个自变量与 $y$ 的线性关系都显著。其回归系数的 $t$ 检验
则是对每个自变量与因变量 $y$ 的线性关系分别进行单独检验。

### 线性关系显著性检验

当多元回归模型估计出来后，还需对整个模型的显著性进行检验。对多元线性回归方程显著性的 $F$ 检验就是要检验自变量
 $x_1,x_2,\cdots,x_p$ 从整体上对随机变量 $y$ 是否有明显的影响。其检验步骤为：

第一步，提出假设。

$${H_0}:{\beta _1} = {\beta _2} =  \cdots  = {\beta _p} = 0, \;{H_1}:{\beta _1}、{\beta _2}、\cdots、{\beta _p} 
不全为 0 $$ {#eq:model29}

第二步，构建检验的 $F$ 统计量，并计算 $F$ 值。

为了建立对 $H_0$ 进行检验的 $F$ 统计量，仍然同一元线性回归分析一样，利用总离差平方和的分解式 [@eq:model25]，构造
 $F$ 统计量如下：
 
$$F = \frac{SSR/p}{SSE/(n - p - 1)} $$ {#eq:model30} 

### 线性关系显著性检验

在正态假设下，当原假设 ${H_0}:{\beta _1} = {\beta _2} =  \cdots  = {\beta _p} = 0$ 成立时， 服从自由度为
 $(p,n-p-1)$ 的 $F$ 分布。于是，可以利用 $F$ 统计量对回归方程的总体显著性进行检验。对于给定的 $n$ 组数据
 $(x_{i1},x_{i2}, \cdots ,x_{ip};y_i)(i = 1,2 \cdots ,n)$，计算出 $SSR$ 和 $SSE$
 ，进而得到 $F$  的值，
 再由给定的显著性水平 $\alpha$ ,查 $F$ 分布表，得到临界
值 $F_{\alpha} (p,n-p-1)$ 。

第三步，作出统计决策。

当 $F>F_\alpha(p,n-p-1)$ 时，拒绝原假设 $H_0$ ,认为在显著性水平 $\alpha$ 下，
$x_1,x_2,\cdots,x_p$ 对 $y$ 有显著的线性关系，也即认为回归方程是显著的；反之，当
$F \le F_\alpha(p,n-p-1)$ 时，则认为回归方程不显著。

也可以根据 $P$ 值作检验。当 $P$ 值 $\le \alpha$ 时，拒绝原假设 $H_0$ ;当 $P$ 值 $\ge \alpha$ ，不拒绝原假设 $H_0$ 。

### 方差分析表

其计算过程列在如表 \@ref(tab:tab-1) 的方差分析表中，

```{r tab-1, eval=T,results='markup', cache=F}
tab1 <- read.csv('./result/varience analysis.csv')
knitr::kable(tab1, row.names =F, align = "l", caption="多元线性回归方差分析表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

### 回归系数显著性检验

在回归方程通过 $F$ 检验后，还需进行 $t$  检验，其目的是分别检验与回归系数 $\beta_i$  对应的自变量 $x_i$ 对因变量的影响是否显著，以便对自变量的取舍做出正确的判断。其步骤如下：

第一步，提出假设。
$$H_0: \beta_j = 0, j=1,2,\cdots,p\;\;H_1:\beta_j \not= 0,j=1,2,\cdots,p$$ {#eq:model31}

第二步，构建检验的 $t$ 统计量，并计算 $t$ 值。
$${t_j} = \frac{{\mathop {\hat \beta }\nolimits_j }}{{Se(\mathop {\hat \beta }\nolimits_j )}} = \frac{{{{\hat \beta }_j}}}{{\sqrt {{c_{jj}}} \hat \sigma }}\sim t(n - p - 1)$$ {#eq:model32} 
式中，$c_{jj}$ 为矩阵 $(X^T\;X)^{-1}$ 主对角线上第 $j$ 个元素；
$\hat \sigma = \sqrt{{\frac 1 {n-p-1}}{\sum\limits_{i = 1}^n {(y_i-\hat y_i)^2}}}$ 是回归标准差。

### 回归系数显著性检验
第三步，做出统计决策。

当原假设 $H_0: \beta_j=0$ ，成立时，式 [@eq:model32] 构造的统计量 $t_j$ 服从自由度为 $n-p-1$ 的 $t$ 分布。
给定显著性水平 $\alpha$  ，查出临界值 $t_{\alpha/2}$ 。当 $|{t_j}| > t_{\alpha/2}$ 时，拒绝原假设
$H_0: \beta_j=0$ ，认为 $\beta_j$ 显著不为零，自变量 $x_j$ 对因变量y的线性效果显著；
当 $|{t_j}| \le t_{\alpha/2}$ 时，不拒绝原假设 $H_0: \beta_j=0$ ,认为 $\beta_j$ 为零，自变量 $x_j$ 
对因变量 $y$ 的线性效果不显著。
 
## 区间估计
### 回归系数区间估计

当有了参数向量 $\beta_j$ 的估计量 $\hat \beta_j$ 时， $\hat \beta_j$ 与 $\beta_j$ 的接近程度如何？
这就需构造 $\beta_j$ 的一个以 $\hat \beta_j$ 为中心的区间，该区间以一定的概率包含 $\beta_j$ 。

由 ${\hat \beta _j}\sim N({\beta _j},\;\;{c_{jj}}{\sigma ^2}){\rm{ }}(\;j = 0,\;1,\;2,\; \cdots ,\;p)$ ，
可知

$${t_j} = \frac{{\hat \beta }_j - \beta }{{\sqrt {c_{jj}}} {\hat \sigma} }\sim t(n - p - 1)$$ {#eq:model33}

$\beta_j$ 的置信度为 $1-\alpha$ 的置信区间为：

$$({\hat \beta}_j - {t_{\alpha/2}} {\sqrt {c_{jj}}} {\hat \sigma},\;{\hat \beta}_j + {t_{\alpha/2}} {\sqrt {c_{jj}}} {\hat \sigma})$$ {#eq:model34}

# 多元回归方程的预测
## 点预测

### 点预测

在通过了各种检验后，多元线性回归模型便可用于预测。多元线性回归预测与一元线性回归
预测的原理是一致的。当给定一组自变量的值 ${x_0} = {({x_{01}},{x_{02}}, \cdots
,{x_{0p}})^T}$ ，要估计所对应的 $y_0$ ，很自然的想法就是将 ${x_0} =
{({x_{01}},{x_{02}}, \cdots ,{x_{0p}})^T}$ 的值代入到回归方程中去，直接算出
点估计值 $\hat y_0$ ：

$${\hat y_0} = {\hat \beta _0} + {\hat \beta _1}{x_{01}} + {\hat \beta
_2}{x_{02}} + \cdots + {\hat \beta _p}{x_{0p}}$$
 
## 区间预测

### 因变量单个值的区间预测

如果已经知道实际的预测值 $y_0$ ,那么预测误差为

$$e_0=y_0-\hat y_0$$ {#eq:model37}

容易证明，在给定自变量向量 $\boldsymbol x=\boldsymbol x_0$ 的条件下

$$\begin{aligned}E(e_0)&=E(X_0\beta + \varepsilon_0 - X_0 \hat\beta)\\&=E[(\varepsilon_0 - x_0(\hat\beta-\beta)]\\&=E[(\varepsilon_0-x_0({X^T}X)^{-1}X^T\varepsilon]\\&=0\end{aligned}$$ {#eq:model38}
$$\begin{aligned}Var(e_0)&=E(e_0^2)\\&=E[(\varepsilon_0-x_0({X^T}X)^{-1}X^T\varepsilon]^2\\&=\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]\end{aligned}$$ {#eq:model39}

### 统计量

$e_0$服从正态分布，即
$$e_0\sim N(\;0,\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]\;)$$ {#eq:model40}

取随机干扰项的样本估计值 $\hat \sigma^2$ ,可得 $e_0$ 的方差的估计量
$$\hat\sigma_{e_0}^2=\hat\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]$$ {#eq:model41}

构造　$t$　统计量
$$t=\frac{\hat y_0-y_0}{\hat\sigma_{e_0}}\sim t(n-p-1)$$ {#eq:model42}

### 结果

可得给定 $1-\alpha$ 的置信水平下 $Y_0$ 的置信区间：

$$\left[\hat y_0-t_{\alpha/2}\times \hat \sigma \sqrt{1+x_0(X^TX)^{-1}x_0^T},\hat y_0+t_{\alpha/2}\times \hat \sigma \sqrt{1+x_0(X^TX)^{-1}x_0^T}\right]$$ {#eq:model43}


### 因变量均值的区间预测

从参数估计值性质的讨论中易知，在 $\boldsymbol x=\boldsymbol x_0$ 的条件下

$$E(\hat y_0)=E(x_0\hat\beta)=x_0E(\hat \beta)=x_0\beta=E(y_0)$$ {#eq:model44}
$$Var(\hat y_0)=E[(x_0\hat\beta-x_0\beta)^2]=E[x_0(\hat\beta_0-\beta_0)x_0(\hat\beta_0-\beta_0)]$$ {#eq:model45}

由于 $x_0(\hat\beta_0-\beta_0)^T$ 为标量，因此

$$\begin{aligned}Var(\hat y_0)&=E[x_0(\hat\beta_0-\beta_0)(\hat\beta_0-\beta_0)^T{x_0}^T]\\&=x_0E[(\hat\beta_0-\beta_0)(\hat\beta_0-\beta_0)^T]{x_0}^T\\&=\sigma^2x_0(X^TX)^{-1}{x_0}^T\end{aligned}$$ {#eq:model46}

容易证明
$$\hat y_0\sim N(x_0\beta,\sigma^2x_0({X^T}X)^{-1}{x_0}^T)$$ {#eq:model47}

### 结果

取随机干扰项的样本估计量 $\hat \sigma^2$ ，可构造如下 $t$ 统计量:

$${\frac {\hat y_0-E(y_0)} {{\hat \sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}}\sim t(n-p-1)$$ {#eq:model48}

于是，得到 $1-\alpha$ 的置信度下 $E(y_0)$ 的置信区间：

$$\left[\hat y_0-t_{\alpha/2} \times {{\hat
\sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}, \hat y_0+t_{\alpha/2} \times {{\hat \sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}\right]$$ {#eq:model49}


# 方差分析
## 方差分析模型
### 方差分析的数据结构

-   现有一个因素$A$，其有$s$个水平分别为$A_{1},\cdots,A_{s}$。

-   实验指标
    用$Y$表示，那么分别对应于每个因素水平的总体可以用$Y_{1},\cdots,Y{s}$来
    表示。

-   假设$Y_{1},\cdots,Y_s$ 独立且均服从方差相等的正态分布， 即
    $$\label{eq:1}
      Y_{j} \overset{\mathrm{i.i.d}}{\sim} \mathcal{N}(\mu_{j},\sigma^{2}),
      \quad j=1,\cdots,s.$$ 其中$\mu_{j}$和$\sigma^{2}$未知。

-   在各个总体$Y_{j},j=1,\cdots,s$中都抽取
    一个简单随机样本$y_{1j},y_{2j}\cdots,y_{n_{j}j}$。我们可以把各个水平下
    的样本放在表中，这样可以更清楚地显示方差分析的数据结构。

### 数据结构表

\begin{table}[h]
  \vskip -2ex
  \centering
  \small
  \caption{单因素方差分析数据结构}
  \vskip 0.2em
  \begin{tabular}{>{\centering\arraybackslash}p{2cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}}
    \toprule
    \multirow{2}[4]{*}{\textbf{观测值}} &
    \multicolumn{4}{c}{\textbf{因素$A$的水平}}  \\
    \cmidrule(l){2-5}
    &$A_{1}$ &$A_{2}$  & $\ldots$ &$A_{s}$  \\
    \midrule
    &$ y_{11}$   & $y_{12}$& $\ldots$      & $y_{1s}$ \\
    &$ y_{21}$    &$y_{22}$       & $\ldots$      &$y_{2s}$  \\
    &$ \vdots$    & $\vdots$      & $\ddots$      &$\vdots$  \\
    &$y_{n_{1}1}$     &$y_{n_{2}2}$       &   $\ldots$    &  $y_{n_{s}s}$\\
    \midrule
    \textbf{样本均值}    & $\bar y_{.1}$    & $\bar y_{.2}$      &
    $\ldots$      &$\bar y_{.s}$  \\
    \textbf{总体均值}    & $\mu_{1}$    &  $\mu_{2}$     &  $\ldots$     &$\mu_{s}$  \\
    \bottomrule
  \end{tabular}%
  \label{tab:2}
\end{table}

### 方差分析的统计模型

-   单因素方差分析的统计模型为 
$$\label{eq:7}
      \left .
      \begin{array}{l}
      y_{ij}=\mu+\alpha_{j}+\varepsilon_{ij},\\
      \displaystyle \sum_{j=1}^{s}n_{j}\alpha_{j}=0,\quad
      i=1,\cdots,n_{j};j=1,\cdots,s,\\
      \varepsilon_{ij} \overset{\text{i.i.d}}{\sim}
      \mathcal{N}(0,\sigma^{2}).
      \end{array} \right \}$$

### 方差分析中假设检验的提法

-   方差分析的任务就是利用得到各个水平下样本数据对模
    型检验$s$个总体$\mathcal{N}(\mu_{1},\sigma^{2}),
         \cdots, \mathcal{N}(\mu_{s}, \sigma^{2})$的均值是否相等，

-   即检验假设 
$$\begin{aligned}
      \label{eq:3}
      &H_{0}:\mu_{1}=\mu_{2}=\cdots=\mu_{s}, \\
      &H_{1}:\mu_{1},\mu_{2},\cdots,\mu_{s}\text{不全相等.} \notag\end{aligned}$$

-   或对模型检验假设 
$$\begin{aligned}
      \label{eq:8}
      &H_{0}:\alpha_{1}=\alpha_{2}=\cdots=\alpha_{s}=0, \\
      &H_{1}:\alpha_{1},\alpha_{2},\cdots,\alpha_{s}\text{不全为0.}
	  \notag\end{aligned}$$
	  
### 实例数据
\begin{table}[h]
  \vskip -2ex
  \centering

  \caption{消费者对四个行业的投诉次数}
  \vskip 0.2em
  \begin{tabular}{>{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{1.5cm}
      >{\centering\arraybackslash}p{2cm}}
    \toprule
    \multirow{2}[4]{*}{\textbf{观测值}} & \multicolumn{4}{c}{\textbf{行业}}  \\
    \cmidrule(l){2-5}
    & \textbf{零售业} & \textbf{旅游业} & \textbf{航空公司} & \textbf{家电制造业} \\
    \midrule
    1     & 57    & 68    & 31    & 44 \\
    2     & 66    & 39    & 49    & 51 \\
    3     & 49    & 29    & 21    & 65 \\
    4     & 40    & 45    & 34    & 77 \\
    5     & 34    & 56    & 40    & 58 \\
    6     & 53    & 51    &       &  \\
    7     & 44    &       &       &  \\
    \bottomrule
  \end{tabular}%
  \label{tab:3-1}
\end{table}

## 方差分析写成线性模型形式

### 方差分析的线性模型
如何把方差分析写成线性模型
$$\boldsymbol{Y=X\beta+\varepsilon}$$


```{r eval=F, echo=T}
model.matrix(~Species, iris)
model.matrix(~Species-1, iris)
### 更改参考水平
model.matrix(~relevel(Species,ref = "virginica"), iris)
```

# 参考文献
[//]: # (\bibliography{Bibfile})




