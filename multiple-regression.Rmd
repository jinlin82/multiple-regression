---
title: "多元线性回归"
author: ""
date: "2019-03"
output:
  bookdown::html_document2:
    number_sections: true
    seq_numbering: true
    fig_caption: true
    highlight: haddock
    theme: null
    md_extensions: +east_asian_line_breaks
    keep_md: true
    toc: true
    pandoc_args: ["--filter", "pandoc-crossref", "-M", "eqnPrefix="]
  bookdown::word_document2:
    fig_caption: true
    reference_docx: ./style/word-styles-02.docx
    md_extensions: +east_asian_line_breaks
    pandoc_args: ["--filter", "pandoc-crossref"]
  bookdown::pdf_document2:
    keep_tex: yes
    toc: false
    latex_engine: xelatex
    md_extensions: +east_asian_line_breaks
    pandoc_args: ["--listing", "--filter", "pandoc-crossref"]
css: ./style/markdown.css
autoEqnLabels: true
eqnPrefixTemplate: ($$i$$)
linkReferences: true
bibliography: Bibfile.bib
csl: ./style/chinese-gb7714-2005-numeric.csl
link-citations: true
---


```{r setup, echo=F}
knitr::opts_knit$set(root.dir = getwd())
knitr::opts_chunk$set(echo = FALSE, results = 'hide')
knitr::opts_chunk$set(warning = FALSE, message=FALSE)
```

```{r prepare}
rm(list=ls())
options(digits=4)
options(scipen=100)
graphics.off()
Sys.setlocale("LC_ALL", "Chinese")
```

# 多元线性回归模型及其基本假定

研究一个随机变量与多个自变量之间线性回归问题的统计分析方法称多元线性回归。一元线性回归分析介绍了因变
量 $y$ 与一个自变量 $x$ 有关的线性回归问题，但在实际应用中，因为客观现象非常复杂，现象之间的联系方式和性质各
不相同，影响因变量变化的自变量往往是多个而不是一个。如果仅仅进行一元回归分析，是不能得到满意的结果的。
因此，有必要将一个因变量与多个自变量联系起来进行分析。如影响农作物收获量的因素，除了施肥量外，还有耕
作深度、降雨量、土质等因素，可以分析各个因素的变化对农作物收获量变化的影响程度。

在线性相关条件下，研究两个和两个以上自变量对一个因变量的数量变化关系，称为多元线性回归分析，表现这一
数量关系的数学表达式则称为多元线性回归模型。多元线性回归分析的基本原理与一元线性回归分析相同，只是涉
及的自变量多，在计算上比较麻烦一些而已。本节将重点介绍多元线性回归模型及其基本假设、回归模型未知参数
的估计及其性质、回归方程及回归系数的显著性检验等。多元回归的计算量要比一元回归的大得多，一般采用计算
机软件完成计算。

## 多元线性回归模型的基本形式

多元线性回归模型是指描述因变量 $y$ 与一组自变量 $x_1,x_2, \ldots ,x_p$ 以及随机误差项 $\varepsilon$的
关系的等式。其一般表达式为：

$$y = \beta _0 + \beta _1{x_1} + \beta _2{x_2} +  \cdots  +\beta _p{x_p}+ \varepsilon$$ {#eq:model1}

式中， $\beta_0,\beta_1,\beta_2,\cdots,\beta_p$ 是 $p+1$ 个未知参数， $\beta_0$ 称为回归截距， 
$\beta_1,\cdots,\beta_p$称为回归系数。 $y$称为被解释变量（因变量），而 $x_1,x_2,\dots,x_p$
是p个可以精确测量并可控制的自变量，称为解释变量。 $p=1$时，式 [@eq:model1] 即为一元线性回归模型， 
 $p \ge 2$ 时，则称式 [@eq:model1] 为多元线性回归模型。
 
对于一个实际问题，如果获得 $n$ 组观测数据 $(x_{i1},x_{i2}, \cdots ,x_{ip};y_i)(i = 1,2 \cdots ,n)$ ，
则线性回归模型式 [@eq:model1] 可表示为：

$$\left\{ \begin{array}{l}
y_1 = \beta _0 + \beta _1{x_{11}} + \beta _2{x_{12}} +  \cdots \beta _p{x_{1p}} + \varepsilon _1\\
y_2 = \beta _0 + \beta _1{x_{21}} + \beta _2{x_{22}} +  \cdots \beta _p{x_{2p}} + \varepsilon _2\\
 \cdots  \cdots  \cdots  \cdots \\
y_n = \beta _0 + \beta _1{x_{n1}} + \beta _2{x_{n2}} +  \cdots \beta _p{x_{np}} + \varepsilon _n
\end{array} \right.$$ {#eq:model2}

写成矩阵形式为： 

$$Y = X{\boldsymbol {\beta}}  + {\boldsymbol {\varepsilon}} $$ {#eq:model3}

式中，

$$Y = \left[ \begin{array}{c} y_1\\y_2\\\vdots \\y_n \end{array} \right],
X = \left[ \begin{array}{c} 1&x_{11}&x_{12}&\cdots&x_{1p}\\ 1&x_{21}&x_{22}&\cdots&x_{2p}\\
\vdots & \vdots & \vdots & \ddots & \vdots \\ 1&x_{n1}&x_{n2}&\cdots&x_{np}\end{array} \right],
\beta  = \left[ \begin{array}{l} \beta _0\\ \beta _1\\ \vdots \\ \beta _p \end{array} \right],
\varepsilon  = \left[ \begin{array}{l} \varepsilon _1\\ \varepsilon _2\\ \vdots \\ \varepsilon _n
\end{array} \right]$$ {#eq:model4}


矩阵 $X$ 是一个 $n \times (p+1)$ 的矩阵，人们常称 $X$ 。公式 [@eq:model1] 中的 
$\varepsilon$ 是随机误差，与一元线性回归的假定类似，对随机误差项也假定：

$$\left\{ \begin{array}{l} E(\varepsilon ) = 0\\ Var(\varepsilon ) = \sigma ^2 \end{array} 
\right.$$ {#eq:model5}


## 多元线性回归模型的基本假定

为了方便地进行模型的参数估计，对回归方程式 [@eq:model2] 有如下的基本假定：

(1)解释变量 $x_1,x_2,\cdots,x_p$ 是确定性变量，即非随机变量，且要求 $rank(X)=p+1<n$ 。
这表明设计矩阵 $X$ 中的自变量列之间不相关，且样本容量的个数 $n$ 应大于自变量的个数 $p$ ，
$X$ 是列满秩矩阵。

(2)随机误差项具有零均值和等方差，即:

$$\left\{ \begin{array}{l}
E({\varepsilon _i}) = 0,\;\;i = 1,\;2,\;\cdots ,\;n\\
{{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = \left\{ \begin{array}{l}
{\sigma ^2},\;\;i = j\\
0,\;i \ne j
\end{array} \right.\;\;\;\;\;\;\;(i,\;j = 1,\;2,\;\cdots,\;n)
\end{array} \right.$$ {#eq:model6}


这个假定常称为高斯－马尔可夫条件。 $E({\varepsilon _i}) = 0$ ，即假设观测值没有系统误差，随机误差 $\varepsilon_i$  
的平均值为零。 $${\mathop{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = 0,i \ne j$$ ，即随机误差 $\varepsilon _i$ 
的协方差为0,表明任意不同的两个样本的随机误差项是不相关的。 $${\mathop{\rm cov}} ({\varepsilon _i},{\varepsilon _j}) = {\sigma ^2}(i = j)$$
表明各随机误差项的方差相同，即各误差项有相同的精度。

(3)正态分布的假定条件为：

$$\left\{ \begin{array}{l}
{\varepsilon _i}\sim N(0,\;{\sigma ^2}),\;\;i = 1,\;2,\; \cdots ,\;n\\
{\varepsilon _1},{\varepsilon _2}, \cdots ,{\varepsilon _n}
\end{array} \right.$$ {#eq:model7}


对于多元线性回归的矩阵形式 [@eq:model3]，这个条件便可表示为：

$$\boldsymbol {\varepsilon} \sim N(0,\sigma^2I_n)$$ {#eq:model8}

由上述假定和多元正态分布的性质可知，随机向量 $Y$ 服从 $n$ 维正态分布，回归模型式 [@eq:model3] 的期望向量

$$\begin{array}{l}E(Y)=X\;\boldsymbol{\beta}\\Var(Y)=\sigma^2I_n\end{array}$$ {#eq:model9}

因此有

$$Y\sim N(X\;\boldsymbol\beta,\sigma^2I_n)$$ {#eq:model10}


## 总体回归方程

对于给定的 $X$ ，因变量 $Y$ 是随机变量，有多个不同的取值，这些不同的取值服从正态分布。
而 $Y$ 的条件期望值 $E(Y|X)$ 是 $X$ 的线性函数，以下将条件期望 $E(Y|X)$ 简记为 $E(Y)$ 。即

$$E(Y)=X\;\boldsymbol\beta$$ {#eq:model11}

或

$$E(y)=\beta _0 + \beta _1{x_1} + \beta _2{x_2} +  \cdots  +\beta _p{x_p}$$ {#eq:model12}

式 [@eq:model12] 称为总体回归方程或理论回归方程，式 [@eq:model11] 是式 [@eq:model12] 的矩阵表达。式 [@eq:model12] 
中， $\beta_0$ 为截距，是 $x_1,x_2,\cdots,x_p = 0$ 时 $y$ 的平均值。如模型不包含 $x_1,x_2,\cdots,x_p = 0$ ， 
 $\beta_0$ 只是回归方程的截距项，没有实际的经济意义； $\beta_1, \beta_2, \cdots, \beta_p$ 称为偏回归系数，
在 $\beta_1, \beta_2, \cdots, \beta_{i-1}, \beta_{i+1}, \cdots, \beta_p$ 保持不变，为一常数时，则有

$$\frac{\partial E(y)}{\partial x_i} = \beta _i$$ {#eq:model13}

即 $\beta_i$ 表示在其它自变量保持不变的前提条件下，$x_i$ 每变动一个单位时因变量 $y$ 的平均水平的变动量。
总体回归方程从平均意义上描述了变量 $y$ 与 $x_i$ 之间的统计规律。

对于回归方程式 [@eq:model12] 的图形，已不像一元线性回归时那样是一条直线，当 $p=2$ 是一个回归平面。当 $p\ge2$ 
时，无法用几何图形表示。 

# 多元线性回归模型参数的估计

## 样本多元线性回归函数

多元线性回归方程的参数 $\beta_0, \beta_1, \cdots, \beta_p$ 是未知的，需要利用样本数据去估计它们。当用样
本统计量 $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 去估计线性回归方程的参数 
$\beta_0, \beta_1, \cdots, \beta_p$ 时，得到了估计的多元回归方程,即样本多元线性回归函数。其一般表达形式

$$\hat y = \hat \beta_0 + \hat \beta _1 x_1 + \cdots + \hat \beta _p x_p $$ {#eq:model14}

其随机表达式为

$$y=\hat \beta_0 + \hat \beta _1 x_1 + \cdots + \hat \beta _p x_p + e$$ {#eq:model15}

式中，$\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 为参数 $\beta_0, \beta_1, \cdots, \beta_p$  的
估计值； $\hat y$ 为 $E(y)$ 的估计值； $e$ 为 $\varepsilon$ 的估计值。 

## 参数的最小二乘估计及性质

### 模型参数的估计

多元线性回归方程参数的估计与一元线性回归方程的参数估计原理一样，仍然采用最小二乘估计法。

即寻找参数 $\beta_0, \beta_1, \cdots, \beta_p$ 的估计值 ，使离差平方和

$$ Q = \sum\limits_{i = 1}^n {\mathop {(\mathop y\nolimits_i  - \mathop {\hat y}\nolimits_i )}\nolimits^2 } 
= \sum\limits_{i = 1}^n {{{({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} 
-  \cdots  - {{\hat \beta }_p}{x_{ip}})}^2}} $$ {#eq:model16}

达到最小。

由于式 [@eq:model16] 是关于 $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 的非负二次函数，因而它的最小
值总是存在的。根据微积分中求极值的原理， $\hat \beta _0, \hat \beta _1, \cdots , \hat \beta _p$ 应满足
下列方程组：

$$\left\{ \begin{array}{l}
\frac{{\partial Q}}{{\partial {\beta _0}}}{|_{{\beta _0} = {{\hat \beta }_0}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}})}  = 0\\
\frac{{\partial Q}}{{\partial {\beta _1}}}{|_{{\beta _1} = {{\hat \beta }_1}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{i1}}}  = 0\\
\frac{{\partial Q}}{{\partial {\beta _2}}}{|_{{\beta _2} = {{\hat \beta }_2}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{i2}}}  = 0\\
 \cdots  \cdots  \cdots \\
\frac{{\partial Q}}{{\partial {\beta _p}}}{|_{{\beta _p} = {{\hat \beta }_p}}} =  - 2\sum\limits_{i = 1}^n {({y_i} - {{\hat \beta }_0} - {{\hat \beta }_1}{x_{i1}} - {{\hat \beta }_2}{x_{i2}} -  \cdots  - {{\hat \beta }_p}{x_{ip}}){x_{ip}}}  = 0
\end{array} \right.$$ {#eq:model17}

以上方程组经整理后，得到用矩阵形式表示的正规方程组：

$${X^T}(Y - X\hat {\boldsymbol{\beta}} ) = 0$$ {#eq:model18}

移项得：

$${X^T}X\hat {\boldsymbol{\beta}}  = {X^T}Y$$ {#eq:model19}

当 $({X^T}X)^{ - 1}$ 存在时，即得模型参数的最小二乘估计为：

$$\hat {\boldsymbol{\beta}}  = ({X^T}X)^{ - 1}{X^T}Y$$ {#eq:model20}

依照式 [@eq:model20]求解 $\hat \beta _0, \hat \beta _1,\hat \beta _2,\cdots , \hat \beta _p$ 的表达式称为模型参数
$\beta_0,\beta_1,\beta_2,\cdots, \beta_p$ 的最小二乘估计量。

### 最小二乘估计量的性质

与一元线性回归模型类似，多元线性回归模型中模型参数的最小二乘估计量也是随机变量。数学上可以证明，在基本
假定条件可以满足时，多元回归模型中模型参数的最小二乘估计量是最优线性无偏估计量。

(1) 线性性

 ${\boldsymbol{\beta}}$ 是随机向量 $Y$ 的一个线性变换，应用普通最小二乘法估计得到的回归系数向量 ${\boldsymbol{\beta}}$ 的估
计量为：

$$\hat {\boldsymbol{\beta}}  = ({X^T}X)^{ - 1}{X^T}Y$$ {#eq:model21}

根据回归模型假设知，$X$ 是固定的设计矩阵，因此， $\hat {\boldsymbol{\beta}}$ 是 $Y$ 的一个线性变换。

(2) $\hat {\boldsymbol{\beta}}$ 是 ${\boldsymbol{\beta}}$ 的无偏估计。

证明：

$$\begin{equation}\begin{aligned}
E(\hat {\boldsymbol{\beta}}) &= E[({X^T}X)^{ - 1}{X^T}Y]\\&=({X^T}X)^{ - 1}{X^T}E(X{\boldsymbol{\beta}}  + {\boldsymbol{\varepsilon}})
\\&=({X^T}X)^{ - 1}({X^T}X){\boldsymbol{\beta}}\\&={\boldsymbol{\beta}}
\end{aligned}\end{equation}$$ {#eq:model22}


(3) 有效性

最优一词的含义就是指方差最小。给定一群线性无偏估计量，普通最小二乘估计量的方差最小。

模型参数最小二乘估计量的方差、协方差矩阵为：

$$\begin{equation}\begin{aligned} 
D(\hat {\boldsymbol{\beta}} ) &= {\mathop{\rm cov}} (\hat {\boldsymbol{\beta}} ,\;\hat {\boldsymbol{\beta}} ) 
\\&= E(\hat {\boldsymbol{\beta}}  - \hat {\boldsymbol{\beta}} )(\hat {\boldsymbol{\beta}}  - \hat {\boldsymbol{\beta}} )^T
\\&= \sigma ^2({X^T}X)^{ - 1}
\end{aligned}\end{equation}$$ {#eq:model23}


证明：

$$\begin{equation}\begin{aligned}
D(\hat {\boldsymbol{\beta}} ) &= {\mathop{\rm cov}} (\hat {\boldsymbol{\beta}},\;\hat {\boldsymbol{\beta}} ) 
\\&= ({X^T}X)^{ - 1}X^T {\mathop{\rm cov}}(Y,Y)(({X^T}X)^{ - 1}X^T)^T
\\&=({X^T}X)^{ - 1}X^T \sigma ^2X({X^T}X)^{ - 1}
\\&=\sigma ^2({X^T}X)^{- 1}\end{aligned}\end{equation}$$ {#eq:model24}


该矩阵主对角元素是各回归系数估计量的方差 ，其他元素是各模型参数估计量之间的协方
差$E(\hat \beta _i - \beta_i)(\hat \beta _j - \beta _j)\;\;(i \ne j)$ 。

## 多元线性回归函数的拟合优度

样本复决定系数是指在多元回归分析中，回归平方和与总离差平方和之比，记为 $R^2$ 。该统计量可作为评价模
型拟合优度的一项指标。

利用总离差平方和的分解式:

$$\sum\limits_{i = 1}^n {(y_i - \bar y)^2}  = \sum\limits_{i = 1}^n {({\hat y}_i - \bar y)}^2  + 
\sum\limits_{i = 1}^n {(y_i - {\hat y}_i)}^2 $$ {#eq:model25}

上式可写为： $ 总离差平方和(SST)=回归平方和(SSR)+残差平方和(SSE) $ ,可得到样本复决定系数的计算公
式为：

$$R^2 = \frac{SSR}{SST} = 1 - \frac{SSE}{SST}$$ {#eq:model26}


由样本复决定系数的定义可知，$R^2$ 的大小取决于残差平方和SSE在总离差平方和SST中所占的比重。在样本容量一定
的条件下，总离差平方和与自变量的个数无关，而残差平方和则会随着模型中自变量个数的增加而不断减少，至少不会
增加。因此， 是自变量个数的非递减函数。在一元线性回归模型中，所有模型包含的变量数目都相同，如果使用的样本
容量也一样，样本决定系数便可以直接作为评价拟合优度的指标。然而，在多元线性回归模型中，各回归模型所含的变
量的数目未必相同，以 $R^2$ 的大小作为衡量模型拟合优度的指标就不太合适。因此，在多元回归分析中应该使用自由
度调整后的决定系数，即利用各自的自由度对总离差平方和与残差平方和进行调整，然后再计算调整后的决定系数 $\bar R^2$ 。

$$\bar R^2 = 1 - \frac{SSE/(n - p - 1)}{SST/(n - 1)} = 1 - \frac{n - 1}{n - p - 1}(1 - R^2)$$ {#eq:model27}

显然有 $\bar R^2 \le R^2$ , $\bar R^2$ 随着自变量的增加并不一定增大。由式 [@eq:model27] 可以看到，尽管 $1-R^2$ 
随着自变量个数的增加而减少，但由于其前面的系数 $(n-1)/(n-p-1)$ 起加权作用，使 $\bar R^2$ 随着自变量的增加并
不一定增大。当所增加的自变量对回归的贡献很小时， $\bar R^2$ 反而可能减少。

样本决定系数 $R^2$ 的取值在[0，1]区间内，由式 [@eq:model27] 可知 $\bar R^2$ 小于1，但不一定都大于0，在拟合极差
的场合， $\bar R^2$ 可能为负值。一般而言， $\bar R^2$ 越接近1，表明拟合效果越好; $\bar R^2$  越接近0或小于0表明
回归拟合的效果越差。

## 总体方差的估计

除了回归系数以外，多元线性回归模型中还包含了随机误差项的方差 $\sigma^2$ 这个未知参数。与一元线性回归
分析相似，多元线性回归模型中的 $\sigma^2$ 也是利用残差平方和除以其自由度来估计的，即有

$${\hat \sigma ^2} = \frac{{SSE}}{{n - p - 1}} = \frac{{\sum\limits_{i = 1}^n {\mathop {(\mathop y\nolimits_i  - \mathop {\hat y}\nolimits_i )}\nolimits^2 } }}{{n - p - 1}}$$ {#eq:model28} 

式中， $n$ 是样本容量, $p$ 是模型中自变量个数， $\hat \sigma^2$ 是随机误差项方差 $\sigma^2$ 的无偏估计量。

# 多元线性回归中的显著性检验和参数区间估计

## 显著性检验

与一元线性回归分析同理，当求出估计的线性回归方程后，还需对回归系数的显著性进行 $t$ 检验和对回归方程的显著性进行  
 $F$ 检验。多元线性回归方程的显著性检验，与一元线性回归方程的显著性检验既有相同之处，也有不同之处。在一元线性回
归中，回归方程的 $F$ 检验与回归系数的 $t$ 检验是等价的。但在多元线性回归分析中，这两种检验是不等价的。多元线性
回归分析中的 $F$ 检验主要是检验因变量 $y$ 与多个自变量整体线性关系的显著性，在 $p$ 个自变量中，只要有一个自变量
与 $y$ 线性关系显著， $F$ 检验就能通过，但并不意味着 $p$ 个自变量与 $y$ 的线性关系都显著。其回归系数的 $t$ 检验
则是对每个自变量与因变量 $y$ 的线性关系分别进行单独检验。

### 线性关系显著性检验

当多元回归模型估计出来后，还需对整个模型的显著性进行检验。对多元线性回归方程显著性的 $F$ 检验就是要检验自变量
 $x_1,x_2,\cdots,x_p$ 从整体上对随机变量 $y$ 是否有明显的影响。其检验步骤为：

第一步，提出假设。

$${H_0}:{\beta _1} = {\beta _2} =  \cdots  = {\beta _p} = 0, \;{H_1}:{\beta _1}、{\beta _2}、\cdots、{\beta _p} 
不全为 0 $$ {#eq:model29}


第二步，构建检验的 $F$ 统计量，并计算 $F$ 值。

为了建立对 $H_0$ 进行检验的 $F$ 统计量，仍然同一元线性回归分析一样，利用总离差平方和的分解式 [@eq:model25]，构造
 $F$ 统计量如下：
 
$$F = \frac{SSR/p}{SSE/(n - p - 1)} $$ {#eq:model30} 


在正态假设下，当原假设 ${H_0}:{\beta _1} = {\beta _2} =  \cdots  = {\beta _p} = 0$ 成立时， 服从自由度为
 $(p,n-p-1)$ 的 $F$ 分布。于是，可以利用 $F$ 统计量对回归方程的总体显著性进行检验。对于给定的 $n$ 组数据
 $(x_{i1},x_{i2}, \cdots ,x_{ip};y_i)(i = 1,2 \cdots ,n)$，计算出 $SSR$ 和 $SSE$ ，进而得到 $F$  的值，其
计算过程列在如表 \@ref(tab:tab-1) 的方差分析表中，再由给定的显著性水平 $\alpha$ ,查 $F$ 分布表，得到临界
值 $F_{\alpha} (p,n-p-1) $。

```{r tab-1, eval=T,results='markup', cache=F}
tab1 <- read.csv('.\\result\\varience analysis.csv')
knitr::kable(tab1, row.names =F, align = "l", caption="方差分析表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```


第三步，作出统计决策。

当 $F>F_\alpha(p,n-p-1)$ 时，拒绝原假设 $H_0$ ,认为在显著性水平 $\alpha$ 下， $x_1,x_2,\cdots,x_p$ 对 $y$ 有显著的线性关系，也即认为回归方程是显著的；反之，当 $F \le F_\alpha(p,n-p-1)$时，则认为回归方程不显著。

与一元线性回归一样，也可以根据 $P$ 值作检验。当 $P$ 值 $\le \alpha$ 时，拒绝原假设 $H_0$ ;当 $P$ 值 $\ge \alpha$ ，不拒绝原假设 $H_0$ 。

### 回归系数显著性检验

在回归方程通过 $F$ 检验后，还需进行 $t$  检验，其目的是分别检验与回归系数 $\beta_i$  对应的自变量 $x_i$ 对因变量的影响是否显著，以便对自变量的取舍做出正确的判断。

多元线性回归模型中回归系数的 $t$  检验，其原理和基本步骤与一元回归模型中的 $t$ 检验基本相同。其步骤如下：

第一步，提出假设。

$$H_0: \beta_j = 0, j=1,2,\cdots,p\;\;H_1:\beta_j \not= 0,j=1,2,\cdots,p$$ {#eq:model31}


第二步，构建检验的 $t$ 统计量，并计算 $t$ 值。

$${t_j} = \frac{{\mathop {\hat \beta }\nolimits_j }}{{Se(\mathop {\hat \beta }\nolimits_j )}} = \frac{{{{\hat \beta }_j}}}{{\sqrt {{c_{jj}}} \hat \sigma }}\sim t(n - p - 1)$$ {#eq:model32} 


式中，$c_{jj}$ 为矩阵 $(X^T\;X)^{-1}$ 主对角线上第 $j$ 个元素；
$\hat \sigma = \sqrt{{\frac 1 {n-p-1}}{\sum\limits_{i = 1}^n {(y_i-\hat y_i)^2}}}$ 是回归标准差。

第三步，做出统计决策。

当原假设 $H_0: \beta_j=0$ ，成立时，式 [@eq:model32] 构造的统计量 $t_j$ 服从自由度为 $n-p-1$ 的 $t$ 分布。
给定显著性水平 $\alpha$  ，查出临界值 $t_{\alpha/2}$ 。当 $|{t_j}| > t_{\alpha/2}$ 时，拒绝原假设
$H_0: \beta_j=0$ ，认为 $\beta_j$ 显著不为零，自变量 $x_j$ 对因变量y的线性效果显著；
当 $|{t_j}| \le t_{\alpha/2}$ 时，不拒绝原假设 $H_0: \beta_j=0$ ,认为 $\beta_j$ 为零，自变量 $x_j$ 
对因变量 $y$ 的线性效果不显著。
 
## 区间估计

当有了参数向量 $\beta_j$ 的估计量 $\hat \beta_j$ 时， $\hat \beta_j$ 与 $\beta_j$ 的接近程度如何？
这就需构造 $\beta_j$ 的一个以 $\hat \beta_j$ 为中心的区间，该区间以一定的概率包含 $\beta_j$ 。

由 ${\hat \beta _j}\sim N({\beta _j},\;\;{c_{jj}}{\sigma ^2}){\rm{ }}(\;j = 0,\;1,\;2,\; \cdots ,\;p)$ ，
可知

$${t_j} = \frac{{\hat \beta }_j - \beta }{{\sqrt {c_{jj}}} {\hat \sigma} }\sim t(n - p - 1)$$ {#eq:model33}

仿照一元线性回归系数区间估计的推导过程，可得 $\beta_j$ 的置信度为 $1-\alpha$ 的置信区间为：

$$({\hat \beta}_j - {t_{\alpha/2}} {\sqrt {c_{jj}}} {\hat \sigma},\;{\hat \beta}_j + {t_{\alpha/2}} {\sqrt {c_{jj}}} {\hat \sigma})$$ {#eq:model34}


使用SPSS软件进行回归分析时，通过选项可以直接得到回归系数的置信区间。

# 多元回归方程的预测

建立回归模型的目的是为了应用，而预测是回归模型最重要的应用之一。下面主要讨论如何根据自变量的取值来对因
变量进行预测。

## 点预测

在通过了各种检验后，多元线性回归模型便可用于预测。多元线性回归预测与一元线性回归预测的原理是一致的，其基
本方程式为：
                    
$${\hat y_i} = {\hat \beta _0} + {\hat \beta _1}{x_{i1}} + {\hat \beta _2}{x_{i2}} +  \cdots  + {\hat \beta _p}{x_{ip}}\;\;\;\;\;\;\;\;\;\;\;\;\;\;i = 1,\;2, \cdots ,n$$ {#eq:model35}

当给定一组自变量的值 ${x_0} = {({x_{01}},{x_{02}}, \cdots ,{x_{0p}})^T}$ ，要估计所对应的 $y_0$ ，很自然的
想法就是将 ${x_0} = {({x_{01}},{x_{02}}, \cdots ,{x_{0p}})^T}$ 的值代入到回归方程中去，直接算出 $\hat y_0$ ：

$${\hat y_0} = {\hat \beta _0} + {\hat \beta _1}{x_{01}} + {\hat \beta _2}{x_{02}} +  \cdots  + {\hat \beta
_p}{x_{0p}}\;\;\;\;\;\;\;\;\;\;\;\;\;\;(i = 1,\;2, \cdots ,n)$$ {#eq:model36}
 
## 区间预测

严格地说， ${\hat y} _0$ 只是被解释变量预测值的估计值，而不是预测值。原因在于模型中参数估计量的不确
定性及随即干扰项的影响两个方面。因此，为了进行科学预测，还需求出预测值的置信区间，包括点预测值 $y_0$ 
和均值 $E(y_0)$ 的置信区间。

### 因变量单个值的区间预测

如果已经知道实际的预测值 $y_0$ ,那么预测误差为

$$e_0=y_0-\hat y_0$$ {#eq:model37}

容易证明，在 $x=x_0$ 的条件下

$$\begin{equation}\begin{aligned}E(e_0)&=E(X_0\beta + \varepsilon_0 - X_0 \hat\beta)\\&=E[(\varepsilon_0 - x_0(\hat\beta-\beta)]\\&=E[(\varepsilon_0-x_0({X^T}X)^{-1}X^T\varepsilon]\\&=0\end{aligned}\end{equation}$$ {#eq:model38}

$$\begin{equation}\begin{aligned}Var(e_0)&=E(e_0^2)\\&=E[(\varepsilon_0-x_0({X^T}X)^{-1}X^T\varepsilon]^2\\&=\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]\end{aligned}\end{equation}$$ {#eq:model39}
 
 $e_0$服从正态分布，即
 
$$e_0\sim N(\;0,\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]\;)$$ {#eq:model40}

取随机干扰项的样本估计值 $\hat \sigma^2$ ,可得 $e_0$ 的方差的估计量

$$\hat\sigma_{e_0}^2=\hat\sigma^2[1+x_0({X^T}X)^{-1}x_0^T]$$ {#eq:model41}

构造　$t$　统计量

$$t=\frac{\hat y_0-y_0}{\hat\sigma_{e_0}}\sim t(n-k-1)$$ {#eq:model42}

可得给定 $1-\alpha$ 的置信水平下 $Y_0$ 的置信区间：

$$\hat y_0-t_{\alpha/2}\times \hat \sigma \sqrt{1+x_0(X^TX)^{-1}x_0^T}<y_0<\hat y_0+t_{\alpha/2}\times \hat \sigma \sqrt{1+x_0(X^TX)^{-1}x_0^T}$$ {#eq:model43}


### 因变量均值的区间预测

从参数估计值性质的讨论中易知，在 $X=X_0$ 的条件下

$$E(\hat y_0)=E(x_0\hat\beta)=x_0E(\hat \beta)=x_0\beta=E(y_0)$$ {#eq:model44}

$$Var(\hat y_0)=E[(x_0\hat\beta-x_0\beta)^2]=E[x_0(\hat\beta_0-\beta_0)x_0(\hat\beta_0-\beta_0)]$$ {#eq:model45}

由于 $x_0(\hat\beta_0-\beta_0)$ 为标量，因此

$$\begin{equation}\begin{aligned}Var(\hat y_0)&=E[x_0(\hat\beta_0-\beta_0)(\hat\beta_0-\beta_0)^T{x_0}^T]\\&=x_0E[(\hat\beta_0-\beta_0)(\hat\beta_0-\beta_0)^T]{x_0}^T\\&=\sigma^2x_0(X^TX)^{-1}{x_0}^T\end{aligned}\end{equation}$$ {#eq:model46}

容易证明

$$\hat y_0\sim N(x_0\beta,\sigma^2x_0({X^T}X)^{-1}{x_0}^T)$$ {#eq:model47}


取随机干扰项的样本估计量 $\hat \sigma^2$ ，可构造如下 $t$ 统计量:

$${\frac {\hat y_0-E(y_0)} {{\hat \sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}}\sim t(n-p-1)$$ {#eq:model48}

于是，得到 $1-\alpha$ 的置信度下 $E(y_0)$ 的置信区间：

$$\hat y_0-t_{\alpha/2} \times {{\hat \sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}<E(y_0)<\hat y_0+t_{\alpha/2} \times {{\hat \sigma}{\sqrt{x_0({X^T}X)^{-1}{x_0}^T}}}$$ {#eq:model49}

# 多元线性回归方程的应用

【例】为研究国内生产总值和固定资产投资、就业人数和社会消费品零售总额的关系，收集了1990-2014年我国的国
内生产总值、固定资产投资、就业人数以及社会消费品零售总额的数据如表 \@ref(tab:tab-2) 所示：

```{r tab-2, eval=T,results='markup', cache=F}
tab2 <- read.csv('.\\result\\exampledata.csv')
knitr::kable(tab2, row.names =F, align = "l", caption="影响我国1990-2014年国内生产总值的主要因素",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```


要求：1.以国内生产总值(亿元)(y)为因变量，固定资产投资(亿元)(x1)、就业人数(万人(x2)和社会消费品零售总额(亿元)
(x3)为自变量，拟合影响国内生产总值的多元回归方程，并对回归方程进行检验，并解释模型的经济意义。2.尝试用所得模
型对2015-2017年的国内生产总值进行预测。

解：1.表 \@ref(tab:tab-2) 中的数据，国内生产总值、固定资产投资、社会消费品零售总额都是按现价核算的，需对数
据进行处理，因为它们都包含了价格变动因素的影响，因此需剔除价格影响后再建模估计参数。表 \@ref(tab:tab-3) 
已经对数据进行处理，即先依据《中国统计年鉴2015》中对应的各价格指数计算整理获得GDP价格定基指数（1990年为100）、
固定资产投资价格定基指数（1990年为100)和社会商品零售价格指数（1990年为100)；然后用现价数据除以相应的定基
价格指数，得到剔除价格影响之后的数据。

```{r tab-3, eval=T,results='markup', cache=F}
tab3 <- read.csv('.\\result\\example data.csv')
knitr::kable(tab3, row.names =F, align = "l", caption="影响我国历年GDP的主要因素",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

设回归模型为：

$$y_t  = \beta _0 + \beta_1x_1 + \beta_2x_2 + \beta_3x_3 + \varepsilon_t $$

根据表 \@ref(tab:tab-3) 中的数据，本例采用SPSS19.0进行数据处理。

（1）启动SPSS19.0版本，建立数据文件“1990-2014年影响我国国内生产总值的各因素数据”。

（2）点击“Analyze”下拉菜单，选中“Regression”中的“Linear”；

（3）在对话窗口中，根据箭头指示方向将“国内生产总值”作为因变量选入“Dependent”方框，将“固定资产投资”、“就业
人数”和“社会消费品零售总额”作为自变量选入“Independent”方框；在“Linear Regression”对话窗口中点击“statistics”按钮，
出现“statistics”对话窗口，选中其中的回归系数区间估计（Confidence Intervals），点击“continue”，返回“Linear 
Regression”对话窗口；再在“Linear Regression”对话窗口中点击“save”按钮，出现“save”对话窗口，选中其中的均值
和单个值的区间估计（Prediction Intervals），点击“continue”，返回“Linear Regression”对话窗口。

（4）点击“OK”按钮，得到下列输出结果：

```{r tab-4, eval=T,results='markup', cache=F}
tab4 <- read.csv('.\\result\\result A regression method.csv')
knitr::kable(tab4, row.names =F, align = "l", caption="回归方法表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```


表 \@ref(tab:tab-4) 为回归方法表。说明进入回归模型或者从回归模型中剔除的变量。本例中进入回归分析的因变量为
国内生产总值，自变量为固定资产投资、就业人数和社会消费品零售总额；回归分析方法是强制回归法，即选取的自变量
都进入回归方程，不论其回归系数是否通过显著性检验。

```{r tab-5, eval=T,results='markup', cache=F}
tab5 <- read.csv('.\\result\\result B model.csv')
knitr::kable(tab5, row.names =F, align = "l", caption="模型综述表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

表 \@ref(tab:tab-5) 为模型综述表。从上表中可知复相关系数、判决系数以及调整后的判决系数分别为 `r tab5[1,2]`、
`r tab5[1,3]`、`r tab5[1,4]`，标准误为 `r tab5[1,2]` ，因此可以初步判断模型拟合得较好。

```{r tab-6, eval=T,results='markup', cache=F}
tab6 <- read.csv('.\\result\\result C ANOVA.csv')
knitr::kable(tab6, row.names =F, align = "l", caption="方差分析表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

表 \@ref(tab:tab-6) 为方差分析表。从该表可知： $F=$ `r tab6[1,4]`，$P$ 值为 `r tab6[1,4]` 。 $F$ 值和 $P$  
值显示整个回归方程有效，即1990-2014年间我国固定资产投资、就业人数和社会消费品零售总额对国内生产总值线性关
系显著，进一步肯定了表 \@ref(tab:tab-5) 的结论。

```{r tab-7, eval=T,results='markup', cache=F}
tab7 <- read.csv('.\\result\\result D coefficient.csv')
knitr::kable(tab7, row.names =F, align = "l", caption="回归系数表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

表 \@ref(tab:tab-7) 为回归系数表。从该表可知自变量的回归系数的估计值及其标准差、 $t$ 检验值、 $P$ 值以及
回归系数的95%的置信区间。

利用表 \@ref(tab:tab-3) 的数据，对模型做最小二乘估计，得估计的回归方程如下

$$\mathop {\hat y}\nolimits_i  = {\rm{ - }}100548.3247{\rm{ + }}0.08{x_1}{\rm{ + }}1.8795{x_2} + 0.0557{x_3}$$ {#eq:model50}

 
由回归方程可知各因素对因变量的影响程度，其中当就业人数和社会消费品零售总额保持不变，固定资产投资每增加1
亿元，国内生产总值平均0.08亿元；当固定资产投资和社会消费品零售总额保持不变，就业人数每增加1万人，国内生
产总值平均1.8795亿元；当固定资产投资和就业人数保持不变，社会消费品零售总额每增加1亿元，国内生产总值平均
增加约0.0577亿元。

从表 \@ref(tab:tab-7) 我们还可以看到各系数在95%的置信水平下的置信区间：固定资产投资的回归系数95%的置信区
间为（`r tab7[3,6]` ， `r tab7[3,7]`）；就业人数的回归系数95%的置信区间为（`r tab7[4,6]` ， `r tab7[4,7]`）；
社会消费品零售总额的回归系数95%的置信区间为（`r tab7[5,6]` , `r tab7[5,7]`）。

需要说明的是：根据经济理论，投资、就业人数、社会消费品零售总额对国内生产总值的影响应该是显著的，但在本例
估计的结果中，固定资产投资和社会消费品零售总额没有通过显著性检验，这可能是因为模型不满足基本假定，比如因
为使用的是时序数据可能存在自相关问题，或许还存在异方差、共线性问题。对于这些问题怎样检验以及模型进一步修
正的方法，请查阅计量经济学中相关内容。

2.利用以上所得模型对2015-2017年的不变价国内生产总值进行预测。

(1)不变价国内生产总值个值预测：

```{r include=FALSE}
#一、读取数据
data=tab2
colnames(data)=c("year","gdp","invest","employment","consume","gdpdex","investdex","consumedex")
#二、数据处理，剔除价格因素影响
newdata=data.frame(data$year,data$gdp/data$gdpdex*100,data$invest/data$investdex*100,data$employment,data$consume/data$consumedex*100)
colnames(newdata)=c("year","gdp","invest","employment","consume")
#三、模型拟合
fit=lm(gdp~invest+employment+consume,newdata)#lm函数需要的是数据框，若是矩阵需要转换
beta=fit$coefficients
#六、模型预测
##1.点预测
predict=read.csv("./result/predict.csv")
x1=as.matrix(predict[,c(3,4,5)])
x0=cbind(rep(1,3),x1)
y0=as.matrix(predict[,2])
haty0=x0%*%beta

#predict()与fitted.values()在没有新数据时，效果一样，都是输出拟合值
```

$$\mathop {\hat y}\nolimits_{2015}= {\rm{ - }}100548.3247{\rm{ + }}0.08\times206921.9{\rm{ + }}1.8795\times77451 + 0.0557\times140267.8=69387.50$$

$$\mathop {\hat y}\nolimits_{2016}= {\rm{ - }}100548.3247{\rm{ + }}0.08\times224616.9{\rm{ + }}1.8795\times77603 + 0.0557\times153826.8=71844.02$$

$$\mathop {\hat y}\nolimits_{2017}= {\rm{ - }}100548.3247{\rm{ + }}0.08\times224444.7{\rm{ + }}1.8795\times77640 + 0.0557\times167708.4=72672.99$$


表 \@ref(tab:tab-8) 给出了2015-2017年剔除价格因素影响的不变价数据，比较显示真实值与预测值之间存在较大偏差，
这进一步说明不满足基本假定的模型拟合效果欠佳。

```{r tab-8, eval=T,results='markup', cache=F}
tab8 <- read.csv('.\\result\\predict.csv')
knitr::kable(tab8, row.names =F, align = "l", caption="预测表",
      longtable = TRUE, booktabs = TRUE, linesep  = "")
```

(2)根据公式 [@eq:model43] 和公式 [@eq:model49] 可分别计算2015年不变价国内生产总值个值和均值的区间预测：

```{r include=FALSE}
#六、模型预测
##2.方差估计
sigma=sqrt(sum((fit$residuals)^2)/21)
sigma

##3.置信区间估计函数
###公式计算
x2=as.matrix(newdata[,c(3,4,5)])
x=cbind(rep(1,length(newdata$year)),x2)
fun=function(x0){
  upper1=x0%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0)%*%solve((t(x)%*%x))%*%x0))#个值预测
  lower1=x0%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0)%*%solve((t(x)%*%x))%*%x0))
  upper2=x0%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(t(x0)%*%solve((t(x)%*%x))%*%x0))#均值预测
  lower2=x0%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(t(x0)%*%solve((t(x)%*%x))%*%x0))
  conf=data.frame(lower1,upper1,lower2,upper2)
}
conf=apply(x0,1,fun)
new=predict[,c(3,4,5)]
new
##4.利用predict计算置信区间
predict(fit,new,interval="none")#个值预测
predict(fit,new,interval="confidence")#均值区间预测
predict(fit,new,interval="prediction")#个值区间预测，与3通过计算得出的置信区间相同
```

2015年GDP个值预测区间: $69390.03 \pm 2.08\times 3703.43$ =(`r x0[1,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[1,])%*%solve((t(x)%*%x))%*%x0[1,]))`，`r x0[1,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[1,])%*%solve((t(x)%*%x))%*%x0[1,])) `);

2015年GDP均值预测区间：$69390.03 \pm 2.08\times 2284.14$ =(`r x0[1,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(t(x0[1,])%*%solve((t(x)%*%x))%*%x0[1,]))`，`r x0[1,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(t(x0[1,])%*%solve((t(x)%*%x))%*%x0[1,])) `);

2016年GDP个值预测区间: $71846.60 \pm 2.08\times 3778.49$ =(`r x0[2,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[2,])%*%solve((t(x)%*%x))%*%x0[2,]))`，`r x0[2,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[2,])%*%solve((t(x)%*%x))%*%x0[2,])) `);

2016年GDP均值预测区间: $71846.60 \pm 2.08\times 2403.94$ =(`r x0[2,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(t(x0[2,])%*%solve((t(x)%*%x))%*%x0[2,]))`，`r x0[2,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(t(x0[2,])%*%solve((t(x)%*%x))%*%x0[2,])) `);

2016年GDP个值预测区间: $72675.07 \pm 2.08\times 7248.97$ =(`r x0[3,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[3,])%*%solve((t(x)%*%x))%*%x0[3,]))`，`r x0[3,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(1+t(x0[3,])%*%solve((t(x)%*%x))%*%x0[3,])) `);

2016年GDP均值预测区间: $72675.07 \pm 2.08\times 6676.28$ =(`r x0[3,]%*%beta-qt(0.975,df=21)*sqrt(sigma^2*(t(x0[3,])%*%solve((t(x)%*%x))%*%x0[3,]))`，`r x0[3,]%*%beta+qt(0.975,df=21)*sqrt(sigma^2*(t(x0[3,])%*%solve((t(x)%*%x))%*%x0[3,])) `).

结果显示，GDP真实值均落在个值预测区间内，但2015年和2016年的均值预测区间未包含真实值，应考虑模型基本假定后重
新构建模型进行拟合，以得到更好的预测效果。

# 参考文献
[//]: # (\bibliography{Bibfile})
